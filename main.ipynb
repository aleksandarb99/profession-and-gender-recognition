{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+DhshLEacRY/pGVA+9OLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksandarb99/profession-and-gender-recognition/blob/develop/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ce3iCP67wZw",
        "outputId": "7413554e-8422-4c84-ab9d-c3ed94f2e0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cao\n"
          ]
        }
      ],
      "source": [
        "print(\"cao\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "from io import open\n",
        "import requests\n",
        "import shutil\n",
        "import numpy as np\n",
        "import json\n",
        "from IPython.display import Image\n",
        "from zipfile import ZipFile\n",
        "import keras\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers import Conv2D, Activation, Dropout, Flatten, Dense, MaxPooling2D\n",
        "from keras import backend as k \n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.python.keras.preprocessing import image\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "lsc1pkOo7zo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f961d8bf-b1d2-434c-d74f-7dd01dc9cbf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execution_path = os.getcwd()\n",
        "print(execution_path)\n",
        "DATASET_DIR = os.path.join(execution_path, \"idenprof\")\n",
        "DATASET_TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
        "DATASET_TEST_DIR = os.path.join(DATASET_DIR, \"test\")\n",
        "\n",
        "!ls \"/content/drive/profession-detection-master\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWoACOTj-OCY",
        "outputId": "d1bab9d0-0598-45a9-a826-639a51bd4ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "ls: cannot access '/content/drive/profession-detection-master': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_direc = os.path.join(os.getcwd(), 'idenprof_models')\n",
        "\n",
        "# Name of model files\n",
        "model_name = 'idenprof_weight_model_VGG19.{epoch:03d}-{val_acc}.h5'\n",
        "\n",
        "# Create Directory if it doesn't exist\n",
        "if not os.path.isdir(save_direc):\n",
        "    os.makedirs(save_direc)\n",
        "# Join the directory with the model file\n",
        "modelpath = os.path.join(save_direc, model_name)\n",
        "\n",
        "# Checkpoint to save best model\n",
        "checkpoint = ModelCheckpoint(filepath = modelpath, monitor = 'val_acc', verbose = 1, save_best_only = True,\n",
        "                             save_weights_only = True, period=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKqSdS6K-k-u",
        "outputId": "9baf1428-26cd-4f53-a22a-c1399152f599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "\n",
        "model = Sequential(\n",
        "    [Conv2D(64, (3, 3), input_shape=input_shape, padding='same',activation='relu'),\n",
        "     Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "     Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "     Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
        "     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "     Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "     MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "     Flatten(),\n",
        "     Dense(10, activation=\"softmax\")])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4nINqSD-lj4",
        "outputId": "bc78dbbb-49d1-4a1d-f174-e396f563f26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                250890    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,275,274\n",
            "Trainable params: 20,275,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network(model):\n",
        "    print(os.listdir(os.path.join(execution_path, \"idenprof\")))\n",
        "    optimizer = keras.optimizers.Adam(lr=0.01, decay=1e-4)\n",
        "    batch_size = 32\n",
        "    num_classes = 10\n",
        "    epochs = 200\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "    print(\"Using real time Data Augmentation\")\n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255,horizontal_flip=True)\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(DATASET_TRAIN_DIR, target_size=(224, 224),batch_size=batch_size,\n",
        "                                                        class_mode=\"categorical\")\n",
        "    test_generator = test_datagen.flow_from_directory(DATASET_TEST_DIR, target_size=(224, 224), batch_size=batch_size,\n",
        "                                                      class_mode=\"categorical\")\n",
        "    model.fit_generator(train_generator, steps_per_epoch=int(9000 / batch_size), epochs=epochs,\n",
        "                        validation_data=test_generator,validation_steps=int(2000 / batch_size),\n",
        "                        callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "nRQfxapb-nXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_network(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "6TXKWoDI-qXj",
        "outputId": "aa79dc0d-21cb-4999-cd48-c17eda67d321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a13f49770662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-36648177fced>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"idenprof\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/idenprof'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_INDEX = None\n",
        "MODEL_PATH = os.path.join(execution_path, \"idenprof_VGG19_053-0.726.h5\")\n",
        "JSON_PATH = os.path.join(execution_path, \"idenprof_model_class.json\")"
      ],
      "metadata": {
        "id": "F4gj9BCs-rsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(MODEL_PATH)"
      ],
      "metadata": {
        "id": "lTbZs3wX-vW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(lr=0.01, decay=1e-4)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "H7AoLcXu-x48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "test_generator = test_datagen.flow_from_directory(DATASET_TEST_DIR, target_size=(224, 224), batch_size = 32,\n",
        "                                                  class_mode=\"categorical\")\n",
        "loss,accuracy = model.evaluate_generator(test_generator,steps=int(2000 / 32))\n",
        "print(\"Accuracy =\", accuracy)"
      ],
      "metadata": {
        "id": "4KDO1jl4-zn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(x):\n",
        "    x *= (1. / 255)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_zUhcf3u-1sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_predictions(preds, top=5, model_json=\"\"):\n",
        "    global CLASS_INDEX\n",
        "    if CLASS_INDEX is None:\n",
        "        CLASS_INDEX = json.load(open(model_json))\n",
        "    results = []\n",
        "    for pred in preds:\n",
        "        top_indices = pred.argsort()[-top:][::-1]\n",
        "        for i in top_indices:\n",
        "            each_result = []\n",
        "            each_result.append(CLASS_INDEX[str(i)])\n",
        "            each_result.append(pred[i])\n",
        "            results.append(each_result)\n",
        "    return results"
      ],
      "metadata": {
        "id": "P8ZKTvjp-3Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(model,picture):\n",
        "    image_to_predict = image.load_img(picture, target_size=(224, 224))\n",
        "    image_to_predict = image.img_to_array(image_to_predict, data_format=\"channels_last\")\n",
        "    image_to_predict = np.expand_dims(image_to_predict, axis=0)\n",
        "\n",
        "    image_to_predict = preprocess_input(image_to_predict)\n",
        "\n",
        "    prediction = model.predict(x=image_to_predict, steps=1)\n",
        "\n",
        "    predictiondata = decode_predictions(prediction, top=int(5), model_json=JSON_PATH)\n",
        "\n",
        "    for result in predictiondata:\n",
        "        print(str(result[0]), \" : \", str(result[1] * 100))"
      ],
      "metadata": {
        "id": "EdkUfPZZ-4SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "picture = os.path.join(execution_path, \"test-images/1.jpg\")\n",
        "display(Image(filename=picture))\n",
        "run_inference(model,picture)"
      ],
      "metadata": {
        "id": "MYHyspJ3-5j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "picture = os.path.join(execution_path, \"test-images/2.jpg\")\n",
        "display(Image(filename=picture))\n",
        "run_inference(model,picture)"
      ],
      "metadata": {
        "id": "6XW6ZqVQ-63X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "picture = os.path.join(execution_path, \"test-images/3.jpg\")\n",
        "display(Image(filename=picture))\n",
        "run_inference(model,picture)"
      ],
      "metadata": {
        "id": "Kkntqdt6-8Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n1BH8Er--9qb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}